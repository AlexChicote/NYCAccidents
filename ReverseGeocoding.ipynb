{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29230eaf-f66f-4151-9a55-d725c5372291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "import pickle\n",
    "import os\n",
    "import playsound\n",
    "import datetime\n",
    "\n",
    "def play_done_message():\n",
    "    playsound.playsound(\"./data/MamaDoIt.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae5e1450-8bf3-432a-b24b-e92aa3fcb37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing some work...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many for this go around? (multiples of 1000)  10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206000\n",
      "708499 1000\n",
      "207000\n",
      "first206000.pkl has been deleted.\n",
      "Time since last one is 65.1 minutes\n",
      "207000\n",
      "711635 1000\n",
      "208000\n",
      "first207000.pkl has been deleted.\n",
      "Time since last one is 34.94 minutes\n",
      "208000\n",
      "714984 1000\n",
      "209000\n",
      "first208000.pkl has been deleted.\n",
      "Time since last one is 19.4 minutes\n",
      "209000\n",
      "718243 1000\n",
      "210000\n",
      "first209000.pkl has been deleted.\n",
      "Time since last one is 19.46 minutes\n",
      "210000\n",
      "721488 1000\n",
      "211000\n",
      "first210000.pkl has been deleted.\n",
      "Time since last one is 19.35 minutes\n",
      "211000\n",
      "724630 1000\n",
      "212000\n",
      "first211000.pkl has been deleted.\n",
      "Time since last one is 19.43 minutes\n",
      "212000\n",
      "727814 1000\n",
      "213000\n",
      "first212000.pkl has been deleted.\n",
      "Time since last one is 19.16 minutes\n",
      "213000\n",
      "731096 1000\n",
      "214000\n",
      "first213000.pkl has been deleted.\n",
      "Time since last one is 19.27 minutes\n",
      "214000\n",
      "734286 1000\n",
      "215000\n",
      "first214000.pkl has been deleted.\n",
      "Time since last one is 19.26 minutes\n",
      "215000\n",
      "737499 1000\n",
      "216000\n",
      "first215000.pkl has been deleted.\n",
      "Time since last one is 19.24 minutes\n"
     ]
    }
   ],
   "source": [
    "# Your main code\n",
    "print(\"Doing some work...\")\n",
    "geolocator = Nominatim(user_agent=\"NYCAccidentsProject\")\n",
    "total_number=int(input('How many for this go around? (multiples of 1000) '))\n",
    "while total_number%1000 !=0:\n",
    "    total_number=input('How many for this go around? (multiples of 1000) ')\n",
    "date1=datetime.datetime.now()\n",
    "for _ in range(int(total_number/1000)):\n",
    "    \n",
    "    pkl=[file for file in os.listdir() if file.endswith('.pkl')]\n",
    "    with open(pkl[0],'rb') as f:\n",
    "        all_dict=pickle.load(f)   \n",
    "    initial=all_dict['last_row']\n",
    "    print(initial)\n",
    "    final=initial+1000\n",
    "    df=all_dict['info'].iloc[initial:final]\n",
    "    idx=df.index\n",
    "    count=0\n",
    "    for row in idx:\n",
    "        #print(row)\n",
    "        count+=1\n",
    "        if count%1000==0:\n",
    "            print(row,count)\n",
    "        location = geolocator.reverse((df.loc[row, 'latitude'],df.loc[row,'longitude']), exactly_one=True)\n",
    "    #print(type(all_dict['df']),type(location))\n",
    "        time.sleep(0.9)\n",
    "        if location:\n",
    "            all_dict['df'].loc[row,'address']=location[0]\n",
    "        else:\n",
    "            all_dict['df'].loc[row,'address']=\"Nothing\"\n",
    "\n",
    "    all_dict['last_row']=len(all_dict['df'])\n",
    "    print(len(all_dict['df']))\n",
    "    with open(f'first{final}.pkl','wb') as f:\n",
    "        pickle.dump(all_dict,f)\n",
    "    \n",
    "    if pkl[0]:\n",
    "        os.remove(pkl[0])\n",
    "        print(f\"{pkl[0]} has been deleted.\")\n",
    "    else:\n",
    "        print(f\"{pkl[0]} does not exist.\")\n",
    "    date2=datetime.datetime.now()\n",
    "    difference=round((date2-date1).total_seconds()/60,2)\n",
    "    print(f'Time since last one is {difference} minutes')\n",
    "    date1=date2\n",
    "# Play the video when the code is done\n",
    "play_done_message()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e695b140-dbc7-4ee7-9e99-e902b214fac7",
   "metadata": {},
   "source": [
    "## UNIQUE VALUES TO REVERSE GEOCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "421469a8-0b59-4d07-8272-18a123f19ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing some work with uniques...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many for this go around? (multiples of 1000)  1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL : 26000\n",
      "27000\n",
      "first26000unique.pkl has been deleted.\n",
      "Time since last one is 5.71 minutes\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Your main code\n",
    "print(\"Doing some work with uniques...\")\n",
    "geolocator = Nominatim(user_agent=\"NYCAccidentsProject\")\n",
    "total_number=int(input('How many for this go around? (multiples of 1000) '))\n",
    "while total_number%1000 !=0:\n",
    "    total_number=input('How many for this go around? (multiples of 1000) ')\n",
    "date1=datetime.datetime.now()\n",
    "for _ in range(int(total_number/1000)):\n",
    "    \n",
    "    pkl=[file for file in os.listdir() if file.endswith('unique.pkl')]\n",
    "    with open(pkl[0],'rb') as f:\n",
    "        all_dict=pickle.load(f)   \n",
    "    initial=all_dict['last_row']\n",
    "    print('INITIAL :',initial)\n",
    "    final=initial+1000\n",
    "    df=all_dict['info'].iloc[initial:final]\n",
    "    idx=df.index\n",
    "    count=0\n",
    "    for row in idx:\n",
    "        #print(row)\n",
    "        count+=1\n",
    "        if count%1000==0:\n",
    "            print(row,count)\n",
    "        location = geolocator.reverse((df.loc[row, 'lat'],df.loc[row,'long']), exactly_one=True)\n",
    "    #print(type(all_dict['df']),type(location))\n",
    "        time.sleep(0.9)\n",
    "        if location:\n",
    "            all_dict['info'].loc[row,'address']=location[0]\n",
    "        else:\n",
    "            all_dict['info'].loc[row,'address']=\"Nothing\"\n",
    "\n",
    "    all_dict['last_row']=final\n",
    "    print(final)\n",
    "    with open(f'first{final}unique.pkl','wb') as f:\n",
    "        pickle.dump(all_dict,f)\n",
    "    \n",
    "    if f'first{initial}unique.pkl' in os.listdir():\n",
    "        os.remove(f'first{initial}unique.pkl')\n",
    "        print(f\"{f'first{initial}unique.pkl'} has been deleted.\")\n",
    "    else:\n",
    "        print(f\"{f'first{initial}unique.pkl'} does not exist.\")\n",
    "    date2=datetime.datetime.now()\n",
    "    difference=round((date2-date1).total_seconds()/60,2)\n",
    "    print(f'Time since last one is {difference} minutes')\n",
    "    date1=date2\n",
    "# Play the video when the code is done\n",
    "play_done_message()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37a200e-9281-4cdf-b036-e0a9e49f8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEXT TASK: Create storage where to keep all locations.\n",
    "## FINISHING UP AUTOMATING API CALLS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b90cb1-1580-497d-b90d-a84cee3a27dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246052, 3)\n",
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "with open('first216000.pkl','rb') as file:\n",
    "    big_one=pickle.load(file)\n",
    "with open('first27000unique.pkl','rb') as file:\n",
    "    small_one=pickle.load(file)\n",
    "big_one_df=pd.concat([big_one['df'],big_one['info']],axis=1)\n",
    "print(big_one_df[big_one_df.address.isnull()].shape)\n",
    "big_one_df['location']=big_one_df['latitude'].astype(str)+big_one_df['longitude'].astype(str)\n",
    "small_one_df=small_one['info']\n",
    "small_one_df['location']=small_one_df['lat'].astype(str)+small_one_df['long'].astype(str)\n",
    "idx_to_save=big_one_df.index\n",
    "small_one_dict=small_one_df[['address','location']].set_index('location').to_dict()['address']\n",
    "count=0\n",
    "for idx,v in big_one_df[big_one_df.address.isnull()].iterrows():\n",
    "    count+=1\n",
    "    if small_one_dict.get(v['location']):\n",
    "        big_one_df.loc[idx,'address']=small_one_dict.get(v['location'])\n",
    "    if count%50000==0:\n",
    "        print(count)\n",
    "play_done_message()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1039276e-b394-4b38-b4f7-4c3209521495",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_one_df.to_csv('new_locations.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ade8e5-c40a-4536-afdc-e6762fc9be51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      6,      10,      13,      19,      21,      23,      31,      39,\n",
       "            40,      41,\n",
       "       ...\n",
       "       2139023, 2139024, 2139027, 2139029, 2139031, 2139035, 2139037, 2139038,\n",
       "       2139042, 2139045],\n",
       "      dtype='int64', length=462052)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Tryong to figure out how to fill nulls in boroughs and zip_code with values address___\n",
    "big_one_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11bd5621-d2e2-435e-85be-890ba9b29f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/93l9lrgs7qgbn3j0hprgld5m0000gn/T/ipykernel_2060/1698732640.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  crashes=pd.read_csv('/Users/fcbnyc/mystuff/repos/NYCAccidents/data/Motor_Vehicle_Collisions_-_Crashes_20241204.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_date</th>\n",
       "      <th>crash_time</th>\n",
       "      <th>borough</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "      <th>on_street_name</th>\n",
       "      <th>cross_street_name</th>\n",
       "      <th>off_street_name</th>\n",
       "      <th>...</th>\n",
       "      <th>contributing_factor_vehicle_2</th>\n",
       "      <th>contributing_factor_vehicle_3</th>\n",
       "      <th>contributing_factor_vehicle_4</th>\n",
       "      <th>contributing_factor_vehicle_5</th>\n",
       "      <th>collision_id</th>\n",
       "      <th>vehicle_type_code_1</th>\n",
       "      <th>vehicle_type_code_2</th>\n",
       "      <th>vehicle_type_code_3</th>\n",
       "      <th>vehicle_type_code_4</th>\n",
       "      <th>vehicle_type_code_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>2:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITESTONE EXPRESSWAY</td>\n",
       "      <td>20 AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4455765</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>11:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QUEENSBORO BRIDGE UPPER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4513547</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>6:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THROGS NECK BRIDGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4541903</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Pick-up Truck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>9:35</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11208.0</td>\n",
       "      <td>40.667202</td>\n",
       "      <td>-73.866500</td>\n",
       "      <td>(40.667202, -73.8665)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1211      LORING AVENUE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4456314</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>8:13</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11233.0</td>\n",
       "      <td>40.683304</td>\n",
       "      <td>-73.917274</td>\n",
       "      <td>(40.683304, -73.917274)</td>\n",
       "      <td>SARATOGA AVENUE</td>\n",
       "      <td>DECATUR STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4486609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  crash_date crash_time   borough zip_code   latitude  longitude  \\\n",
       "0 2021-09-11       2:39       NaN      NaN        NaN        NaN   \n",
       "1 2022-03-26      11:45       NaN      NaN        NaN        NaN   \n",
       "2 2022-06-29       6:55       NaN      NaN        NaN        NaN   \n",
       "3 2021-09-11       9:35  BROOKLYN  11208.0  40.667202 -73.866500   \n",
       "4 2021-12-14       8:13  BROOKLYN  11233.0  40.683304 -73.917274   \n",
       "\n",
       "                  location           on_street_name cross_street_name  \\\n",
       "0                      NaN    WHITESTONE EXPRESSWAY         20 AVENUE   \n",
       "1                      NaN  QUEENSBORO BRIDGE UPPER               NaN   \n",
       "2                      NaN       THROGS NECK BRIDGE               NaN   \n",
       "3    (40.667202, -73.8665)                      NaN               NaN   \n",
       "4  (40.683304, -73.917274)          SARATOGA AVENUE    DECATUR STREET   \n",
       "\n",
       "           off_street_name  ...  contributing_factor_vehicle_2  \\\n",
       "0                      NaN  ...                    Unspecified   \n",
       "1                      NaN  ...                            NaN   \n",
       "2                      NaN  ...                    Unspecified   \n",
       "3  1211      LORING AVENUE  ...                            NaN   \n",
       "4                      NaN  ...                            NaN   \n",
       "\n",
       "   contributing_factor_vehicle_3  contributing_factor_vehicle_4  \\\n",
       "0                            NaN                            NaN   \n",
       "1                            NaN                            NaN   \n",
       "2                            NaN                            NaN   \n",
       "3                            NaN                            NaN   \n",
       "4                            NaN                            NaN   \n",
       "\n",
       "   contributing_factor_vehicle_5  collision_id  vehicle_type_code_1  \\\n",
       "0                            NaN       4455765                Sedan   \n",
       "1                            NaN       4513547                Sedan   \n",
       "2                            NaN       4541903                Sedan   \n",
       "3                            NaN       4456314                Sedan   \n",
       "4                            NaN       4486609                  NaN   \n",
       "\n",
       "   vehicle_type_code_2  vehicle_type_code_3 vehicle_type_code_4  \\\n",
       "0                Sedan                  NaN                 NaN   \n",
       "1                  NaN                  NaN                 NaN   \n",
       "2        Pick-up Truck                  NaN                 NaN   \n",
       "3                  NaN                  NaN                 NaN   \n",
       "4                  NaN                  NaN                 NaN   \n",
       "\n",
       "  vehicle_type_code_5  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crashes=pd.read_csv('/Users/fcbnyc/mystuff/repos/NYCAccidents/data/Motor_Vehicle_Collisions_-_Crashes_20241204.csv')\n",
    "crashes.columns=[col.lower().replace(' ','_') for col in crashes.columns]\n",
    "crashes['crash_date']=pd.to_datetime(crashes.crash_date,format='%m/%d/%Y')\n",
    "crashes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8b4d683-a326-4a4c-a180-e7802c48d1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557153 1309, Forest Avenue, Westerleigh, Staten Island, Richmond County, City of New York, New York, 10302, United States <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "for idx, v in new_crash.sample(30,random_state=111).iterrows():\n",
    "    if (isinstance(v['address___'],str)) and (isninstance(v['borough'],float)):\n",
    "        print(idx,v['address___'],type(v['borough']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7c6b78e-b8f9-42e2-8ed4-4e0e25e8c244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_crash.loc[557153,'borough']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "73096412-5d5d-4e33-8308-bd84fca1564e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "1 0\n",
      "6 0\n",
      "7 Nothing\n",
      "8 0\n",
      "9 0\n",
      "10 0\n",
      "11 0\n",
      "12 0\n",
      "13 0\n",
      "14 0\n"
     ]
    }
   ],
   "source": [
    "# for value in new_crash.address___.sample(30,random_state=111):\n",
    "#     print(value)\n",
    "values_options=set([len(value.split(',')) for value in new_crash.address___ if isinstance(value,str)])\n",
    "print(values_options)\n",
    "for v in values_options:\n",
    "    list_=[value for value in new_crash.address___ if isinstance(value,str) and len(value)==v]\n",
    "    if len(list_)==0:\n",
    "        print(v, len(list_))\n",
    "    else:\n",
    "        print(v,[value for value in new_crash.address___ if isinstance(value,str) and len(value)==v][0])\n",
    "[v for v in new_crash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b71781f-3b7c-4238-bbc2-54962f32155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#big_one_df.columns=[col+'_' for col in big_one_df.columns]\n",
    "new_crash=pd.concat([crashes,big_one_df['address___']],axis=1)\n",
    "new_crash.to_csv('new_crashes_fixed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1da717f-6b69-49bc-b337-2725b916ea42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40.6129575, -73.9590769) nan\n",
      "(40.705154, -73.85597) 40.705154-73.85597\n",
      "(40.8396059, -73.9181388) nan\n",
      "(40.86832, -73.8331589) nan\n",
      "(40.70705, -73.93209) nan\n",
      "(40.5946211, -73.9974189) 40.5946211-73.9974189\n",
      "(40.66612, -73.82225) nan\n",
      "(40.678394, -73.94692) nan\n",
      "(40.688236, -73.76196) nan\n",
      "nan nan\n",
      "(40.7453835, -73.9947093) nan\n",
      "(40.7270902, -73.9766387) nan\n",
      "(40.7460428, -73.8260812) nan\n",
      "(40.736214, -73.713486) nan\n",
      "(40.71285, -73.93457) nan\n",
      "(40.683723, -73.96797) 40.683723-73.96797\n",
      "(40.86749, -73.840515) nan\n",
      "(40.7598833, -73.9367906) nan\n",
      "(40.59406, -73.7891194) nan\n",
      "(40.7057388, -73.9446867) nan\n",
      "(40.701645, -73.73046) nan\n",
      "(40.8658679, -73.8462386) nan\n",
      "(40.81719, -73.93446) nan\n",
      "(40.7879013, -73.9536717) nan\n",
      "(40.699405, -73.953369) nan\n",
      "(40.774853, -73.98067) 40.774853-73.98067\n",
      "(40.7707422, -73.9945485) nan\n",
      "(40.6250313, -73.929483) nan\n",
      "(40.7692226, -73.967306) nan\n",
      "(40.6312149, -74.1005091) nan\n"
     ]
    }
   ],
   "source": [
    "for idx,v in new_crash.sample(30).iterrows():\n",
    "    print(v['location'],v['location__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "397f442d-5365-43dc-9148-ecb724dce7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the number of nulls in borough but that I have lat and long: 462052\n"
     ]
    }
   ],
   "source": [
    "nulls_in_boroughs=new_crash[(new_crash.borough.isnull()) & (new_crash.latitude_.notnull())].shape[0]\n",
    "print(f\"These are the number of nulls in borough but that I have lat and long: {nulls_in_boroughs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcc7c286-965d-4c44-acab-72c9551b5dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TO_DO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m uniques_df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m----> 2\u001b[0m uniques_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m[x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m TO_DO]\n\u001b[1;32m      3\u001b[0m uniques_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m[x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m TO_DO]\n\u001b[1;32m      4\u001b[0m uniques_df\u001b[38;5;241m=\u001b[39muniques_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TO_DO' is not defined"
     ]
    }
   ],
   "source": [
    "uniques_df=pd.DataFrame()\n",
    "uniques_df['lat']=[x.split(',')[0].strip() for x in TO_DO]\n",
    "uniques_df['long']=[x.split(',')[1].strip() for x in TO_DO]\n",
    "uniques_df=uniques_df.iloc[1:]\n",
    "uniques_df['address']='to_fill'\n",
    "uniques_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe53b570-7753-488c-8004-75ddc45deabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df', 'last_row', 'info'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9dfcff38-d512-465d-b90a-e7c5b6838acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict={}\n",
    "new_dict['last_row']=0\n",
    "new_dict['info']=uniques_df\n",
    "with open('final0unique.pkl','wb') as file:\n",
    "    pickle.dump(new_dict,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cb766760-68c5-4d31-a819-6b173bb6b32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_row': 0,\n",
       " 'info':              lat        long  address\n",
       " 1      40.608757  -74.038086  to_fill\n",
       " 2        40.8047   -73.91243  to_fill\n",
       " 3      40.798256   -73.82744  to_fill\n",
       " 4       40.77077   -73.91727  to_fill\n",
       " 5       40.83801   -73.87329  to_fill\n",
       " ...          ...         ...      ...\n",
       " 57930   40.63617  -73.928734  to_fill\n",
       " 57931   40.68361   -73.91172  to_fill\n",
       " 57932  40.659843   -73.94316  to_fill\n",
       " 57933  40.552235   -74.21214  to_fill\n",
       " 57934   40.83305   -73.90592  to_fill\n",
       " \n",
       " [57934 rows x 3 columns]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('final0unique.pkl','rb') as file:\n",
    "    test=pickle.load(file)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b9d7add0-9417-4a5d-a79d-e883ac61cdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.608757</td>\n",
       "      <td>-74.038086</td>\n",
       "      <td>carrer Toledo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.8047</td>\n",
       "      <td>-73.91243</td>\n",
       "      <td>to_fill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.798256</td>\n",
       "      <td>-73.82744</td>\n",
       "      <td>to_fill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.77077</td>\n",
       "      <td>-73.91727</td>\n",
       "      <td>to_fill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40.83801</td>\n",
       "      <td>-73.87329</td>\n",
       "      <td>to_fill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57930</th>\n",
       "      <td>40.63617</td>\n",
       "      <td>-73.928734</td>\n",
       "      <td>to_fill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57931</th>\n",
       "      <td>40.68361</td>\n",
       "      <td>-73.91172</td>\n",
       "      <td>to_fill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57932</th>\n",
       "      <td>40.659843</td>\n",
       "      <td>-73.94316</td>\n",
       "      <td>to_fill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57933</th>\n",
       "      <td>40.552235</td>\n",
       "      <td>-74.21214</td>\n",
       "      <td>to_fill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57934</th>\n",
       "      <td>40.83305</td>\n",
       "      <td>-73.90592</td>\n",
       "      <td>to_fill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57934 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lat        long        address\n",
       "1      40.608757  -74.038086  carrer Toledo\n",
       "2        40.8047   -73.91243        to_fill\n",
       "3      40.798256   -73.82744        to_fill\n",
       "4       40.77077   -73.91727        to_fill\n",
       "5       40.83801   -73.87329        to_fill\n",
       "...          ...         ...            ...\n",
       "57930   40.63617  -73.928734        to_fill\n",
       "57931   40.68361   -73.91172        to_fill\n",
       "57932  40.659843   -73.94316        to_fill\n",
       "57933  40.552235   -74.21214        to_fill\n",
       "57934   40.83305   -73.90592        to_fill\n",
       "\n",
       "[57934 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
